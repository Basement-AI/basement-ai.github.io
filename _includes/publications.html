<section id="publications">
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 text-center">
                <h3 class="section-heading">Papers and Talks</h3>
                <hr class="primary">
                See my publications in: <a title="Google Scholar" href="https://scholar.google.com/citations?user=Vhq5-s0AAAAJ">Google Scholar</a> | <a title="ACL Anthology" href="https://aclanthology.org/people/a/aarne-talman/">ACL Anthology</a> 
                <h4>Peer-Reviewed Papers</h4>
            </div>
                <div class="col-lg-8 col-lg-offset-2 text-left">
                  <ol>
                    <li><b>Aarne Talman</b>, Hande Celikkanat, Sami Virpioja, Markus Heinonen, Jörg Tiedemann. 2023. <a title="Uncertainty-Aware Natural Language Inference with Stochastic Weight Averaging" href="https://aclanthology.org/2023.nodalida-1.37/">Uncertainty-Aware Natural Language Inference with Stochastic Weight Averaging</a>. Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa). [<a href="https://aclanthology.org/2023.nodalida-1.37.bib">bibtex</a>] [<a href="https://aclanthology.org/2023.nodalida-1.37.pdf">pdf</a>] [<a href="https://github.com/Helsinki-NLP/uncertainty-aware-nli">code</a>]</li>
                    <li><b>Aarne Talman</b>, Marianna Apidianaki, Stergios Chatzikyriakidis, Jörg Tiedemann. 2022. <a title="How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets" href="https://aclanthology.org/2022.starsem-1.20/">How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets</a>. Proceedings of the 11th Joint Conference on Lexical and Computational Semantics. [<a href="https://aclanthology.org/2022.starsem-1.20.bib">bibtex</a>] [<a href="https://aclanthology.org/2022.starsem-1.20.pdf">pdf</a>] [<a href="https://github.com/Helsinki-NLP/nlu-dataset-diagnostics">data and code</a>]</li>
                    <li><b>Aarne Talman</b>, Marianna Apidianaki, Stergios Chatzikyriakidis, Jörg Tiedemann. 2021. <a title="NLI Data Sanity Check: Assessing the Effect of Data Corruption on Model Performance" href="https://www.aclweb.org/anthology/2021.nodalida-main.28/">NLI Data Sanity Check: Assessing the Effect of Data Corruption on Model Performance</a>. Proceedings of the 23rd Nordic Conference on Computational Linguistics. [<a href="https://www.aclweb.org/anthology/2021.nodalida-main.28.bib">bibtex</a>] [<a href="https://www.aclweb.org/anthology/2021.nodalida-main.28.pdf">pdf</a>] [<a href="https://github.com/Helsinki-NLP/nli-data-sanity-check">data and code</a>]</li>
                    <li><b>Aarne Talman</b>, Antti Suni, Hande Celikkanat, Sofoklis Kakouros, Jörg Tiedemann and Martti Vainio. 2019. <a title="Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations" href="https://aclweb.org/anthology/W19-6129/">Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations</a>. Proceedings of the 22nd Nordic Conference on Computational Linguistics. [<a href="https://aclweb.org/anthology/W19-6129.bib">bibtex</a>] [<a href="https://www.aclweb.org/anthology/W19-6129.pdf">pdf</a>] [<a href="https://github.com/Helsinki-NLP/prosody">corpus and code</a>]</li>
                    <li><b>Aarne Talman</b>, Umut Sulubacak, Raúl Vázquez, Yves Scherrer, Sami Virpioja, Alessandro Raganato, Arvi Hurskainen, and Jörg Tiedemann. 2019. <a title="The University of Helsinki submissions to the WMT19 news translation task" href="https://www.aclweb.org/anthology/W19-5347"> The University of Helsinki submissions to the WMT19 news translation task</a>. Proceedings of the Fourth Conference on Machine Translation: Shared Task Papers. [<a href="https://www.aclweb.org/anthology/W19-5347.bib">bibtex</a>] [<a href="https://www.aclweb.org/anthology/W19-5347.pdf">pdf</a>]</li>
                    <li><b>Aarne Talman</b> and Stergios Chatzikyriakidis. 2019. <a title="Testing the Generalization Power of Neural Network Models Across NLI Benchmarks" href="https://aclweb.org/anthology/papers/W/W19/W19-4810/">Testing the Generalization Power of Neural Network Models Across NLI Benchmarks</a>. Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. [<a href="https://aclweb.org/anthology/W19-4810.bib">bibtex</a>] [<a href="https://www.aclweb.org/anthology/W19-4810.pdf">pdf</a>]</li>
                    <li><b>Aarne Talman</b>, Anssi Yli-Jyrä and Jörg Tiedemann. 2019. <a title="Sentence Embeddings in NLI with Iterative Refinement Encoders" href="https://www.cambridge.org/core/journals/natural-language-engineering/article/sentence-embeddings-in-nli-with-iterative-refinement-encoders/AC811644D52446E414333B20FEACE00F">Sentence Embeddings in NLI with Iterative Refinement Encoders</a>. Natural Language Engineering 25(4). [<a href="files/hbmp.bib">bibtex</a>] [<a href="https://arxiv.org/pdf/1808.08762.pdf">pdf</a>] [<a href="https://github.com/Helsinki-NLP/HBMP">code</a>]</li>
                </ol>
              </div>
              <div class="col-lg-8 col-lg-offset-2 text-center">
                <h4>Theses</h4>
              </div>
                <div class="col-lg-8 col-lg-offset-2 text-left">
                  <ol>
                    <li><b>Aarne Talman</b>. 2023 (expected). Towards Natural Language Understanding: Developing and Assessing Approaches and Benchmarks. Doctoral Dissertation. University of Helsinki.</li>
                    <li><b>Aarne Talman</b>. 2006. Path Grammars and the Generative Capacity of Dynamic Syntax. Master's Dissertation. King's College London.</li>
                    <li><b>Aarne Talman</b>. 2005. <a title="A Limit on Artificial Intelligence? – The Gödelian Case" href="files/Aarne_Talman_BSc_Thesis.pdf">A Limit on Artificial Intelligence? – The Gödelian Case</a>. Bachelor's Thesis. The London School fo Economics and Political Science.</li>
                  </ol>
                </div>
              <div class="col-lg-8 col-lg-offset-2 text-center">
                <h4>Talks</h4>
              </div>
                <div class="col-lg-8 col-lg-offset-2 text-left">
                  <ol>
                    <li>How Does Data Corruption Affect Natural Language Understanding Models?. 29th September 2022, <a title="Research Seminar in Language Technology" href="https://blogs.helsinki.fi/language-technology/research-seminar-fall-2022/">Research Seminar in Language Technology</a>, University of Helsinki. [<a href="https://blogs.helsinki.fi/language-technology/files/2022/10/LT-seminar-Aarne-Talman-2022-09-15.pdf">pdf</a>]</li>
                    <li>How Does Data Corruption Affect Natural Language Understanding Models? A Study on GLUE datasets. 15th July 2022, <a title="The 11th Joint Conference on Lexical and Computational Semantics" href="https://sites.google.com/view/starsem2022/">The 11th Joint Conference on Lexical and Computational Semantics (*SEM) 2022</a>, Seattle, Washington, USA.</li>
                    <li>NLI Data Sanity Check: Assessing the Effect of Data Corruption on Model Performance. 2 June 2021, <a title="The 23rd Nordic Conference on Computational Linguistics" href="https://nodalida2021.github.io">The 23rd Nordic Conference on Computational Linguistics</a>, Reykjavik. [<a href="files/NoDaLiDa_2021.pdf">pdf</a>]</li>
                    <li>Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations. 14 November 2019, <a title="Research Seminar in Language Technology" href="https://blogs.helsinki.fi/language-technology/research-seminar/">Research Seminar in Language Technology</a>, University of Helsinki. [<a href="files/2019-11-14-Aarne-Talman_Seminar.pdf" >pdf</a>]</li>
                    <li>Predicting Prosodic Prominence from Text with Pre-trained Contextualized Word Representations. 2 October 2019, <a title="The 22nd Nordic Conference on Computational Linguistics" href="https://nodalida2019.org">The 22nd Nordic Conference on Computational Linguistics</a>, Turku. [<a href="files/Talman_NoDaLiDa_Oct_2019.pdf" >pdf</a>]</li>
                    <li>Neural Network models of NLI fail to capture the general notion of inference, 8 March 2019, <a title="CLASP Seminar" href="https://clasp.gu.se/news-events/e/?eventId=70136843492">CLASP Seminar</a>, University of Gothenburg. [<a href="files/Seminar_Gothenburg_March_2019.pdf" >pdf</a>]</li>            
                    <li>State-of-the-Art Natural Language Inference Systems Fail to Capture the Semantics of Inference, 25 October 2018, <a title="Research Seminar in Language Technology" href="https://blogs.helsinki.fi/language-technology/research-seminar/">Research Seminar in Language Technology</a>, University of Helsinki. [<a href="files/Talman_HY-LT-Seminar-Oct-2018.pdf" >pdf</a>]</li>           
                    <li>Natural Language Inference with Hierarchical BiLSTM’s, 28 September 2018, <a title="FoTran 2018" href="https://blogs.helsinki.fi/language-technology/fotran-2018/">FoTran 2018</a>. [<a href="files/FoTran2018-Talman.pdf" >pdf</a>]</li>
                    <li>Natural Language Inference - Another Triumph for Deep Learning?, 23 November 2017, <a title="Research Seminar in Language Technology" href="https://blogs.helsinki.fi/language-technology/research-seminar/">Research Seminar in Language Technology</a>, University of Helsinki. [<a href="files/Talman_HY-LT-Seminar-Nov-2017.pdf" >pdf</a>]</li>
                </ol>
              </div>
            </div>
        </div>
    </div>
</section>
