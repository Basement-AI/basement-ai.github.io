@inproceedings{1730b59e9d4e490d95f2d1fd5b866848,
title = "ELOQUENT 2024 - Topical Quiz Task",
abstract = "ELOQUENT is a set of shared tasks for evaluating the quality and usefulness of generative language models. ELOQUENT aims to apply high-level quality criteria, grounded in experiences from deploying models in real-life tasks, and to formulate tests for those criteria, preferably implemented to require minimal human assessment effort and in a multilingual setting. One of the tasks for the first year of ELOQUENT was the Topical quiz, in which language models are probed for topical competence. This first year of experimentation has shown - as expected - that using self-assessment with models judging models is feasible, but not entirely straight-forward, and that a judicious comparison with human assessment and application context is necessary to be able to trust self-assessed quality judgments.",
keywords = "6121 Languages, 113 Computer and information sciences",
author = "Jussi Karlgren and Aarne Talman",
note = "Publisher Copyright: {\textcopyright} 2024 Copyright for this paper by its authors.; Conference and Labs of the Evaluation Forum, CLEF 2024 ; Conference date: 09-09-2024 Through 12-09-2024",
year = "2024",
language = "English",
series = "CEUR Workshop Proceedings",
publisher = "CEUR-WS.org",
pages = "687--690",
editor = "Guglielmo Faggioli and Ferro, {Nicola } and Galu{\v s}{\v c}{\'a}kov{\'a}, {Petra } and {Garc{\'i}a Seco de Herrera }, {Alba }",
booktitle = "Working Notes of the Conference and Labs of the Evaluation Forum (CLEF 2024)",
address = "Germany",
}